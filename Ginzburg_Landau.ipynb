{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb62982-b44e-4281-b743-9d76f2d8dab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import perf_counter\n",
    "\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from scipy.linalg import LinAlgError, cholesky, issymmetric\n",
    "from scipy.optimize import minimize\n",
    "from tensorflow import convert_to_tensor, keras\n",
    "from tensorflow.keras.constraints import NonNeg\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam, Nadam\n",
    "\n",
    "tf.keras.backend.set_floatx(\"float64\")\n",
    "tf.keras.utils.set_random_seed(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "500781ce-d9db-4a09-8e13-2a61d1866b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x0, xf = -1.0, 1.0\n",
    "y0, yf = -1.0, 1.0\n",
    "\n",
    "t0 = 0.0\n",
    "dt = 0.2\n",
    "tfinal = dt\n",
    "\n",
    "num_polynomials = 4\n",
    "\n",
    "nu = 10.0\n",
    "eps = 4e-3\n",
    "\n",
    "L1 = 30\n",
    "layer_dims = (1 + 2 * num_polynomials, L1, L1, L1, L1, L1, L1, L1, L1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02059ca9-c21b-4fdd-b8ab-533db4f1f4b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PeriodicC0Layer(keras.layers.Layer):\n",
    "    def __init__(self, num_polynomials, **kwargs):\n",
    "        super(PeriodicC0Layer, self).__init__(**kwargs)\n",
    "        \n",
    "        self.num_polynomials = num_polynomials\n",
    "        \n",
    "        # Initialize lists to store trainable variables for each polynomial\n",
    "        self.rx = []\n",
    "        self.sx = []\n",
    "        self.ry = []\n",
    "        self.sy = []\n",
    "        \n",
    "        for i in range(self.num_polynomials):\n",
    "            # For x-dimension\n",
    "            self.rx.append([\n",
    "                self.add_weight(name=f'r{i}0x', initializer=tf.constant_initializer(1.), dtype=tf.float64, trainable=True),\n",
    "                self.add_weight(name=f'r{i}1x', initializer=tf.constant_initializer(1.), dtype=tf.float64, trainable=True)\n",
    "            ])\n",
    "            self.sx.append([\n",
    "                self.add_weight(name=f's{i}0x', initializer=tf.constant_initializer(1.), dtype=tf.float64, trainable=True),\n",
    "                self.add_weight(name=f's{i}1x', initializer=tf.constant_initializer(1.), dtype=tf.float64, trainable=True)\n",
    "            ])\n",
    "            \n",
    "            # For y-dimension\n",
    "            self.ry.append([\n",
    "                self.add_weight(name=f'r{i}0y', initializer=tf.constant_initializer(1.), dtype=tf.float64, trainable=True),\n",
    "                self.add_weight(name=f'r{i}1y', initializer=tf.constant_initializer(1.), dtype=tf.float64, trainable=True)\n",
    "            ])\n",
    "            self.sy.append([\n",
    "                self.add_weight(name=f's{i}0y', initializer=tf.constant_initializer(1.), dtype=tf.float64, trainable=True),\n",
    "                self.add_weight(name=f's{i}1y', initializer=tf.constant_initializer(1.), dtype=tf.float64, trainable=True)\n",
    "            ])\n",
    "        \n",
    "    def call(self, X):\n",
    "        t = X[:, 0,None]  # Time\n",
    "        x = X[:, 1,None]  # x coordinate\n",
    "        y = X[:, 2,None]  # y coordinate\n",
    "        \n",
    "        px_list = []\n",
    "        py_list = []\n",
    "        \n",
    "        for i in range(self.num_polynomials):\n",
    "            p_x = (self.sx[i][0] + self.sx[i][1] * (x - x0) * (xf - x) * (x0 + xf - 2 * x) + \n",
    "                   (self.rx[i][0] + self.rx[i][1] * x) * (x - x0)**2 * (x - xf)**2)\n",
    "            px_list.append(p_x)\n",
    "            p_y = (self.sy[i][0] + self.sy[i][1] * (y - y0) * (yf - y) * (y0 + yf - 2 * y) + \n",
    "                   (self.ry[i][0] + self.ry[i][1] * y) * (y - y0)**2 * (y - yf)**2)\n",
    "            py_list.append(p_y)\n",
    "        \n",
    "        px = tf.concat(px_list, axis=1)\n",
    "        py = tf.concat(py_list, axis=1)\n",
    "        \n",
    "        return tf.concat([t, px, py], axis=1)\n",
    "    \n",
    "\n",
    "def generate_model():\n",
    "    X_input = Input((3,))\n",
    "    Xf = PeriodicC0Layer(num_polynomials)(X_input)\n",
    "    Xf = Dense(L1,activation=\"tanh\")(Xf)\n",
    "    Xf = Dense(L1,activation=\"tanh\")(Xf)\n",
    "    Xf = Dense(L1,activation=\"tanh\")(Xf)\n",
    "    Xf = Dense(L1,activation=\"tanh\")(Xf)\n",
    "    Xf = Dense(L1,activation=\"tanh\")(Xf)\n",
    "    Xf = Dense(L1,activation=\"tanh\")(Xf)\n",
    "    Xf = Dense(L1,activation=\"tanh\")(Xf)\n",
    "    Xf = Dense(L1,activation=\"tanh\")(Xf)\n",
    "    Xf = Dense(2,activation=None)(Xf)\n",
    "    N = Model(inputs=X_input, outputs=Xf)\n",
    "    return N\n",
    "\n",
    "def generate_inputs(Nint,t0,tfinal):\n",
    "    t = (tfinal-t0)*np.random.rand(Nint) + t0\n",
    "    x = (xf-x0)*np.random.rand(Nint) + x0\n",
    "    y = (yf-y0)*np.random.rand(Nint) + y0\n",
    "    Xs = np.hstack((x[:,None],y[:,None]))\n",
    "    X = np.hstack((t[:,None],Xs))\n",
    "    return convert_to_tensor(X)\n",
    "\n",
    "def generate_initial(N0,t0):\n",
    "    t = t0*np.ones(N0)\n",
    "    x = (xf-x0)*np.random.rand(N0) + x0\n",
    "    y = (yf-y0)*np.random.rand(N0) + y0\n",
    "    Xs = np.hstack((x[:,None],y[:,None]))\n",
    "    X = np.hstack((t[:,None],Xs))\n",
    "    return convert_to_tensor(X)\n",
    "    \n",
    "def adaptive_rad(N,Nint,t0,tfinal,rad_args):\n",
    "    Xtest = generate_inputs(50000,t0,tfinal)\n",
    "    k1,k2 = rad_args\n",
    "    _,_,fu,fv = get_results(N,Xtest,t0,tfinal)\n",
    "    Y = tf.math.sqrt(fu**2+fv**2).numpy()\n",
    "    err_eq = np.power(Y,k1)/np.power(Y,k1).mean() + k2\n",
    "    err_eq_normalized = (err_eq / sum(err_eq))\n",
    "    X_ids = np.random.choice(a=len(Xtest), size=Nint, replace=False,\n",
    "                         p=err_eq_normalized) \n",
    "    return tf.gather(Xtest,X_ids)\n",
    "\n",
    "def uinit(X):\n",
    "    x = X[:,1,None]\n",
    "    y = X[:,2,None]\n",
    "    return 10*y*tf.math.exp(-25*(x**2 + y**2))\n",
    "\n",
    "def vinit(X):\n",
    "    x = X[:,1,None]\n",
    "    y = X[:,2,None]\n",
    "    return 10*x*tf.math.exp(-25*(x**2 + y**2))\n",
    "\n",
    "def output(N,X,t0,tfinal):\n",
    "    t = X[:,0,None]\n",
    "    xy = X[:,1:]\n",
    "    tnorm = (2/(tfinal-t0))*t - (tfinal+t0)/(tfinal-t0)\n",
    "    Xnorm = tf.concat([tnorm,xy],axis=1)\n",
    "    Nout = N(Xnorm)\n",
    "    u = Nout[:,0,None]\n",
    "    v = Nout[:,1,None]\n",
    "    return u,v\n",
    "\n",
    "\n",
    "def get_results(N,X,t0,tfinal):\n",
    "   with tf.GradientTape(persistent=True, watch_accessed_variables=False) as gt1:\n",
    "      gt1.watch(X)\n",
    "\n",
    "      with tf.GradientTape(persistent=True, watch_accessed_variables=False) as gt2:\n",
    "         gt2.watch(X)\n",
    "\n",
    "         # Calculate u,v\n",
    "         u,v = output(N,X,t0,tfinal)\n",
    "      \n",
    "      ugrad = gt2.gradient(u, X)\n",
    "      vgrad = gt2.gradient(v, X)\n",
    "      u_t = ugrad[:,0]\n",
    "      u_x = ugrad[:,1]\n",
    "      u_y = ugrad[:,2]\n",
    "      v_t = vgrad[:,0]\n",
    "      v_x = vgrad[:,1]\n",
    "      v_y = vgrad[:,2]\n",
    "      \n",
    "   u_xx = gt1.gradient(u_x, X)[:,1]\n",
    "   v_xx = gt1.gradient(v_x, X)[:,1]\n",
    "   u_yy = gt1.gradient(u_y,X)[:,2]\n",
    "   v_yy = gt1.gradient(v_y,X)[:,2]\n",
    "   hmod = u**2 + v**2\n",
    "   fu = u_t - eps*(u_xx + u_yy) - nu*(u[:,0]-hmod[:,0]*(u[:,0]-1.5*v[:,0]))\n",
    "   fv = v_t - eps*(v_xx + v_yy) - nu*(v[:,0]-hmod[:,0]*(v[:,0]+1.5*u[:,0]))\n",
    "   return u,v,fu,fv\n",
    "\n",
    "lam0 = 100.\n",
    "\n",
    "loss_function = keras.losses.MeanSquaredError()\n",
    "def loss(fu,fv,u0,u0pinn,v0,v0pinn):\n",
    "    Ntot = fu.shape[0]\n",
    "    zeros = tf.zeros([Ntot,1],dtype=tf.float64)\n",
    "    loss_f = loss_function(fu,zeros) + loss_function(fv,zeros)\n",
    "    loss_0 = loss_function(u0,u0pinn) + loss_function(v0,v0pinn)\n",
    "    return loss_f + lam0*loss_0\n",
    "\n",
    "def grads(N,X,X0,u0,v0,t0,tfinal):\n",
    "    with tf.GradientTape() as tape2:\n",
    "        _,_,fu,fv = get_results(N,X,t0,tfinal)\n",
    "        u0pinn,v0pinn = output(N, X0,t0,tfinal)\n",
    "        loss_value = loss(fu,fv,u0,u0pinn,v0,v0pinn)\n",
    "    gradsN = tape2.gradient(loss_value,N.trainable_variables)\n",
    "    return gradsN,loss_value\n",
    "\n",
    "@tf.function() \n",
    "def training(N,X,X0,u0,v0,t0,tfinal,optimizer): \n",
    "    parameter_gradients,loss_value = grads(N,X,X0,u0,v0,t0,tfinal)\n",
    "    optimizer.apply_gradients(zip(parameter_gradients,N.trainable_variables))\n",
    "    return loss_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b5b4f0-dddb-43e3-83eb-84ae4b1b561e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Nepochs = 0\n",
    "Nchange=500\n",
    "Nint = 20000\n",
    "N0 = 5000\n",
    "Nsave = 50\n",
    "N = generate_model()\n",
    "\n",
    "k1 = 1\n",
    "k2 = 0\n",
    "rad_args = (k1,k2) #If random uniform, select k1 = 0\n",
    "loss_list = np.array([])\n",
    "X = generate_inputs(Nint,t0,tfinal)\n",
    "X0 = generate_initial(N0,t0)\n",
    "u0 = uinit(X0)\n",
    "v0 = vinit(X0)\n",
    "\n",
    "lr = tf.keras.optimizers.schedules.ExponentialDecay(5e-3,1000,0.98)\n",
    "\n",
    "optimizer = Adam(lr,0.99,0.999,epsilon=1e-20) #The optimizer\n",
    "template = 'Epoch {}, loss: {}'\n",
    "fname = \"Grad_Shafranov_multipole_combination_Epoch {}_FCN30L3_rmax_10000.h5\"\n",
    "\n",
    "start_time = perf_counter()\n",
    "\n",
    "for i in range(Nepochs):\n",
    "    if (i+1)%Nchange == 0:\n",
    "        X = adaptive_rad(N, Nint, t0, tfinal, rad_args)\n",
    "        X0 = generate_initial(N0,t0)\n",
    "        #X = tf.concat([X,X0],axis=0)\n",
    "        u0 = uinit(X0)\n",
    "        v0 = vinit(X0)\n",
    "    if (i+1)%100 == 0:\n",
    "        _,_,fu,fv = get_results(N,X,t0,tfinal)\n",
    "        u0pinn,v0pinn = output(N, X0, t0, tfinal)\n",
    "        loss_value = loss(fu,fv,u0,u0pinn,v0,v0pinn)\n",
    "        loss_list = np.append(loss_list,loss_value.numpy())\n",
    "        \n",
    "    training(N,X,X0,u0,v0,t0,tfinal,optimizer)\n",
    "\n",
    "\n",
    "\n",
    "adam_end_time = perf_counter()\n",
    "adam_training_time = adam_end_time - start_time\n",
    "print(f\"Total Adam training time: {adam_training_time:.2f} seconds\")\n",
    "\n",
    "with open(f\"adam_training_time.txt\", \"w\") as f:\n",
    "    f.write(f\"Adam Training Time: {adam_training_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016599cd-2a30-41b8-a020-f3f7076ff06a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nested_tensor(grad,layer_dims,train_activations=False,bias=True,num_polynomials=num_polynomials):\n",
    "\n",
    "    if train_activations == False:\n",
    "        if bias:\n",
    "            temp = [None]*(2*len(layer_dims)-2)\n",
    "        else:\n",
    "            temp = [None]*(2*len(layer_dims)-3)\n",
    "            \n",
    "        index = 8*num_polynomials\n",
    "        for i in range(len(temp)):\n",
    "            if i%2==0:\n",
    "                temp[i] = np.reshape(grad[index:index+layer_dims[i//2]*\\\n",
    "                        layer_dims[i//2 +1]],(layer_dims[i//2],\n",
    "                                              layer_dims[i//2 +1]))\n",
    "                index+=layer_dims[i//2]*layer_dims[i//2 +1]\n",
    "            else:\n",
    "                temp[i] = grad[index:index+layer_dims[i-i//2]]\n",
    "                index+=layer_dims[i-i//2]\n",
    "                \n",
    "        for i in range(8*num_polynomials):\n",
    "            temp.insert(i,grad[i])\n",
    "        return temp\n",
    "   \n",
    "    else:\n",
    "        temp = [None]*(3*len(layer_dims)-4)\n",
    "        index = 0\n",
    "        for i in range(len(temp)):\n",
    "            if i%3==0:\n",
    "                temp[i] = np.reshape(grad[index:index+layer_dims[i//3]*\\\n",
    "                        layer_dims[i//3 +1]],(layer_dims[i//3],\n",
    "                        layer_dims[i//3 +1]))\n",
    "                index+=layer_dims[i//3]*layer_dims[i//3 +1]\n",
    "            elif i%3==1:\n",
    "                temp[i] = grad[index:index+layer_dims[int((i+2)/3)]]\n",
    "                index+=layer_dims[int((i+2)/3)]\n",
    "            else:  \n",
    "                temp[i] = grad[index]\n",
    "                index+=1\n",
    "        return temp\n",
    "\n",
    "\n",
    "power = 1. \n",
    "@tf.function\n",
    "def loss_and_gradient_TF(N,X,X0,u0,v0,t0,tfinal): \n",
    "    with tf.GradientTape() as tape:\n",
    "       _,_,fu,fv = get_results(N,X,t0,tfinal)\n",
    "       u0pinn,v0pinn = output(N, X0,t0,tfinal)\n",
    "       loss_value = loss(fu,fv,u0,u0pinn,v0,v0pinn)**(1./power)\n",
    "\n",
    "    gradsN = tape.gradient(loss_value,N.trainable_variables)\n",
    "    return loss_value,gradsN\n",
    "\n",
    "\n",
    "def loss_and_gradient(weights,N,X,X0,u0,v0,t0,tfinal,layer_dims):\n",
    "    resh_weights = nested_tensor(weights,layer_dims)\n",
    "    N.set_weights(resh_weights)\n",
    "    loss_value,grads = loss_and_gradient_TF(N,X,X0,u0,v0,t0,tfinal)\n",
    "    grads_flat = np.concatenate([tf.reshape(g, [-1]).numpy() for g in grads])\n",
    "    return loss_value.numpy(), grads_flat\n",
    "\n",
    "Nbfgs = 60000 \n",
    "Nbatches = int(round(Nbfgs/Nchange))\n",
    "epochs_bfgs = np.arange(0,Nbfgs+100,100) \n",
    "epochs_bfgs+=Nepochs\n",
    "lossbfgs = np.zeros(len(epochs_bfgs)) #loss bfgs list\n",
    "Nprint = 100\n",
    "\n",
    "initial_weights = np.concatenate([tf.reshape(w, [-1]).numpy() \\\n",
    "                                  for w in N.weights]) \n",
    "    \n",
    "lossbfgs = np.array([])\n",
    "\n",
    "cont=0\n",
    "Nsave=50\n",
    "\n",
    "def callback(*,intermediate_result): \n",
    "    global N,cont,lossbfgs\n",
    "    if (cont+1)%100 == 0 or cont == 0:\n",
    "        loss_value = intermediate_result.fun**power\n",
    "        lossbfgs = np.append(lossbfgs,loss_value)\n",
    "        loss_value = intermediate_result.fun**power\n",
    "        print(loss_value,cont+1)\n",
    "    cont+=1\n",
    "    \n",
    "H0 = tf.eye(len(initial_weights),dtype=tf.float64)\n",
    "H0 = H0.numpy()\n",
    "method=\"BFGS\"\n",
    "method_bfgs = \"SSBroyden2\" \n",
    "initial_scale=False \n",
    "\n",
    "\n",
    "cont=0\n",
    "Nslices = int(1/tfinal)\n",
    "cont_slice = 0\n",
    "tol_loss = 1e-10\n",
    "max_iters = 20000\n",
    "iterations_slice = 0\n",
    "Nbfgs = max_iters*Nslices\n",
    "\n",
    "epochs_bfgs = np.arange(0,Nbfgs+100,100)\n",
    "epochs_bfgs+=Nepochs\n",
    "lossbfgs = np.zeros(len(epochs_bfgs)) \n",
    "\n",
    "Nprev = generate_model()\n",
    "resh_weights = nested_tensor(initial_weights, layer_dims)\n",
    "Nprev.set_weights(resh_weights)\n",
    "iterations_slice=0\n",
    "\n",
    "#------------------------- BFGS TRAINING --------------------------------------\n",
    "initial_time_bfgs = perf_counter()\n",
    "while cont_slice < Nslices: \n",
    "    print(\"Change batch\")\n",
    "    result = minimize(loss_and_gradient,initial_weights, args = (N,X,X0,u0,v0,t0,tfinal,layer_dims),\n",
    "          method=method,jac=True, options={'maxiter':Nchange, 'gtol':0, \"hess_inv0\":H0,\n",
    "                                         \"method_bfgs\":method_bfgs,\\\n",
    "                                         \"initial_scale\":initial_scale},\n",
    "          tol=0,callback=callback) \n",
    "        \n",
    "    initial_weights = result.x\n",
    "    H0 = result.hess_inv\n",
    "    H0 = (H0 + np.transpose(H0))/2\n",
    "    try:\n",
    "        cholesky(H0)\n",
    "    except LinAlgError:\n",
    "        H0 = tf.eye(len(initial_weights),dtype=tf.float64)\n",
    "        H0 = H0.numpy()\n",
    "    \n",
    "    X = adaptive_rad(N, Nint, t0, tfinal, rad_args)\n",
    "    X0 = generate_initial(N0,t0)\n",
    "    if result.nit != 0:\n",
    "        iterations_slice+=Nchange\n",
    "    if cont_slice%Nslices == 0:\n",
    "        u0 = uinit(X0)\n",
    "        v0 = vinit(X0)\n",
    "        _,_,fu,fv = get_results(N,X,t0,tfinal)\n",
    "        u0pinn,v0pinn = output(N, X0,t0,tfinal)\n",
    "        loss_value = loss(fu,fv,u0,u0pinn,v0,v0pinn)\n",
    "    else:\n",
    "        u0,v0 = output(Nprev, X0, t0-dt, tfinal-dt)\n",
    "        _,_,fu,fv = get_results(N,X,t0,tfinal)\n",
    "        u0pinn,v0pinn = output(N,X0,t0,tfinal)\n",
    "        loss_value = loss(fu,fv,u0,u0pinn,v0,v0pinn)\n",
    "        \n",
    "    if (loss_value.numpy() < tol_loss or iterations_slice >= max_iters) and result.nit !=0:\n",
    "        Nprev = generate_model()\n",
    "        resh_weights = nested_tensor(initial_weights, layer_dims)\n",
    "        Nprev.set_weights(resh_weights)\n",
    "        N = generate_model()\n",
    "        
    "        N.set_weights(resh_weights)\n",
    "                \n",
    "        cont_slice+=1\n",
    "        t0+=dt\n",
    "        tfinal+=dt\n",
    "        \n",
    "        X = generate_inputs(Nint, t0, tfinal)\n",
    "        X0 = generate_initial(N0,t0)\n",
    "        #X = tf.concat([X,X0],axis=0)\n",
    "        \n",
    "        u0,v0 = output(Nprev, X0, t0-dt, tfinal-dt)\n",
    "        \n",
    "        H0 = tf.eye(len(initial_weights),dtype=tf.float64)\n",
    "        H0 = H0.numpy()\n",
    "        iterations_slice = 0\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (my_env)",
   "language": "python",
   "name": "my_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
