{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ad85781f-ea49-4a84-a9bf-753063e6b6b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "from time import perf_counter\n",
    "\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "from scipy.optimize import minimize\n",
    "from scipy.linalg import cholesky, LinAlgError\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.utils import parameters_to_vector, vector_to_parameters\n",
    "\n",
    "torch.set_default_dtype(torch.float64)\n",
    "torch.manual_seed(2)\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "RESULTS_DIR = \"results2\"\n",
    "os.makedirs(RESULTS_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8f0be838-e5bb-4543-bfc1-24b237526734",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x (8000,) t (8000,) X (8000, 2)\n",
      "Epoch 100, loss: 1.7890767572408994\n",
      "Epoch 200, loss: 0.9908028767179117\n",
      "Epoch 300, loss: 0.36800973930528313\n",
      "Epoch 400, loss: 0.3273272835648765\n",
      "x (50000,) t (50000,) X (50000, 2)\n",
      "Epoch 500, loss: 0.43881018316011816\n",
      "Epoch 600, loss: 0.37473320909341673\n",
      "Epoch 700, loss: 0.3336869346241431\n",
      "Epoch 800, loss: 0.2961261403263739\n",
      "Epoch 900, loss: 0.2674100191166916\n",
      "x (50000,) t (50000,) X (50000, 2)\n",
      "Epoch 1000, loss: 0.34029874991729325\n",
      "x (300, 300) t (300, 300) X (90000, 2)\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'burgers_canonical.mat'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m/oscar/data/gk/ekianiha/my_env/lib64/python3.9/site-packages/scipy/io/matlab/_mio.py:39\u001b[0m, in \u001b[0;36m_open_file\u001b[0;34m(file_like, appendmat, mode)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 39\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfile_like\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;66;03m# Probably \"not found\"\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'burgers_canonical.mat'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 333\u001b[0m\n\u001b[1;32m    330\u001b[0m mask_b \u001b[38;5;241m=\u001b[39m (Xtest[:, \u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m x0) \u001b[38;5;241m|\u001b[39m (Xtest[:, \u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m xf)\n\u001b[1;32m    331\u001b[0m Xbtest \u001b[38;5;241m=\u001b[39m Xtest[mask_b]\n\u001b[0;32m--> 333\u001b[0m mat \u001b[38;5;241m=\u001b[39m \u001b[43mscipy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloadmat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mburgers_canonical.mat\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    334\u001b[0m u_ref  \u001b[38;5;241m=\u001b[39m mat[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124musol\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    335\u001b[0m t_star \u001b[38;5;241m=\u001b[39m mat[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mt\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mravel()\n",
      "File \u001b[0;32m/oscar/data/gk/ekianiha/my_env/lib64/python3.9/site-packages/scipy/io/matlab/_mio.py:225\u001b[0m, in \u001b[0;36mloadmat\u001b[0;34m(file_name, mdict, appendmat, **kwargs)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;124;03mLoad MATLAB file.\u001b[39;00m\n\u001b[1;32m     90\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[38;5;124;03m    3.14159265+3.14159265j])\u001b[39;00m\n\u001b[1;32m    223\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    224\u001b[0m variable_names \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvariable_names\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m--> 225\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _open_file_context(file_name, appendmat) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m    226\u001b[0m     MR, _ \u001b[38;5;241m=\u001b[39m mat_reader_factory(f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    227\u001b[0m     matfile_dict \u001b[38;5;241m=\u001b[39m MR\u001b[38;5;241m.\u001b[39mget_variables(variable_names)\n",
      "File \u001b[0;32m/usr/lib64/python3.9/contextlib.py:119\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 119\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgenerator didn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt yield\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/oscar/data/gk/ekianiha/my_env/lib64/python3.9/site-packages/scipy/io/matlab/_mio.py:17\u001b[0m, in \u001b[0;36m_open_file_context\u001b[0;34m(file_like, appendmat, mode)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;129m@contextmanager\u001b[39m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_open_file_context\u001b[39m(file_like, appendmat, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m---> 17\u001b[0m     f, opened \u001b[38;5;241m=\u001b[39m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_like\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mappendmat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     19\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m f\n",
      "File \u001b[0;32m/oscar/data/gk/ekianiha/my_env/lib64/python3.9/site-packages/scipy/io/matlab/_mio.py:45\u001b[0m, in \u001b[0;36m_open_file\u001b[0;34m(file_like, appendmat, mode)\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m appendmat \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m file_like\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.mat\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m     44\u001b[0m         file_like \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.mat\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m---> 45\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfile_like\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\n\u001b[1;32m     48\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mReader needs file name or open file-like object\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     49\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'burgers_canonical.mat'"
     ]
    }
   ],
   "source": [
    "scaling = 1  \n",
    "L1 = 20\n",
    "layer_dims = (2, L1, L1, L1, L1, 1)\n",
    "\n",
    "L = 2\n",
    "x0 = -1\n",
    "xf = x0 + L\n",
    "tfinal = 1\n",
    "nu = 0.01 / np.pi\n",
    "\n",
    "\n",
    "Nepochs_ADAM  = 1000\n",
    "Nchange  = 500\n",
    "Nint     = 8000\n",
    "N0       = 500\n",
    "Nb       = 500\n",
    "Nprint   = 100\n",
    "\n",
    "k1 = 1  \n",
    "k2 = 1  \n",
    "rad_args = (k1, k2) \n",
    "\n",
    "\n",
    "class CustomActivation(nn.Module):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x * scaling\n",
    "\n",
    "\n",
    "def init_variance_scaling_fan_avg_uniform(linear, scale):\n",
    "    fan_in, fan_out = linear.in_features, linear.out_features\n",
    "    n = 0.5 * (fan_in + fan_out)\n",
    "    limit = math.sqrt(3.0 * scale / n)\n",
    "    with torch.no_grad():\n",
    "        linear.weight.uniform_(-limit, limit)\n",
    "        if linear.bias is not None:\n",
    "            linear.bias.zero_()\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(layer_dims[0], layer_dims[1]), nn.Tanh(),\n",
    "            nn.Linear(layer_dims[1], layer_dims[2]), nn.Tanh(),\n",
    "            nn.Linear(layer_dims[2], layer_dims[3]), nn.Tanh(),\n",
    "            nn.Linear(layer_dims[3], layer_dims[4]), nn.Tanh(),\n",
    "            nn.Linear(layer_dims[4], layer_dims[5]),\n",
    "            CustomActivation(),)\n",
    "        final_linear = self.net[-2]\n",
    "        init_variance_scaling_fan_avg_uniform(final_linear, scale=1.0/(scaling**2))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "N = Net()\n",
    "\n",
    "def generate_inputs(Nint):\n",
    "    t = tfinal * np.random.rand(Nint)\n",
    "    x = L * np.random.rand(Nint) + x0\n",
    "    X = np.hstack((t[:, None], x[:, None]))\n",
    "    print('x', x.shape, 't', t.shape, 'X', X.shape)\n",
    "    return torch.as_tensor(X)\n",
    "\n",
    "def initial_points(N0):\n",
    "    t = np.zeros(N0)\n",
    "    x = L * np.random.rand(N0) + x0\n",
    "    X = np.hstack((t[:, None], x[:, None]))\n",
    "    return torch.as_tensor(X)\n",
    "\n",
    "def boundary_points(Nb):\n",
    "    t = tfinal * np.random.rand(Nb)\n",
    "    x = L * np.random.randint(0, 2, size=(Nb,)) + x0\n",
    "    X = np.hstack((t[:, None], x[:, None]))\n",
    "    return torch.as_tensor(X)\n",
    "\n",
    "def generate_validation(Nt, Nx):\n",
    "    x = np.linspace(x0, xf, Nx)\n",
    "    t = np.linspace(0, tfinal, Nt)\n",
    "    x, t = np.meshgrid(x, t)\n",
    "    X = np.hstack((t.flatten()[:, None], x.flatten()[:, None]))\n",
    "    print('x', x.shape, 't', t.shape, 'X', X.shape)\n",
    "    return torch.as_tensor(X), t, x\n",
    "\n",
    "def adaptive_rad(N, Nint, rad_args, Nsampling=50000):\n",
    "    Xtest = generate_inputs(Nsampling)              \n",
    "    k1, k2 = rad_args\n",
    "    Y = torch.abs(get_results(N, Xtest)[-1]).reshape(-1)  \n",
    "    w = (Y**k1)\n",
    "    err_eq = w / w.mean() + k2\n",
    "    p = (err_eq / err_eq.sum()).clamp_min(1e-12)     \n",
    "    X_ids = torch.multinomial(p, num_samples=Nint, replacement=False)\n",
    "    return Xtest[X_ids]\n",
    "\n",
    "def uinit(X): \n",
    "    x = X[:, 1:2]\n",
    "    return -torch.sin(torch.pi * x)\n",
    "\n",
    "def uleft(X): \n",
    "    Xleft = X[X[:, 1] == x0]\n",
    "    t = Xleft[:, 0]\n",
    "    return torch.zeros((t.shape[0], 1), dtype=torch.float64)\n",
    "\n",
    "def uright(X):  \n",
    "    Xright = X[X[:, 1] == xf]\n",
    "    t = Xright[:, 0]\n",
    "    return torch.zeros((t.shape[0], 1), dtype=torch.float64)\n",
    "\n",
    "def output(N, X):\n",
    "    Nout = N(X)\n",
    "    u = Nout[:, 0:1]\n",
    "    return u\n",
    "\n",
    "def get_results(N, X):\n",
    "    X.requires_grad_(True)\n",
    "    u = output(N, X)                 \n",
    "    grads = torch.autograd.grad(\n",
    "        u, X,\n",
    "        grad_outputs=torch.ones_like(u),\n",
    "        create_graph=True,\n",
    "        retain_graph=True)[0]        \n",
    "    u_t = grads[:, 0]                  \n",
    "    u_x = grads[:, 1]                  \n",
    "\n",
    "    u_xx = torch.autograd.grad(\n",
    "        u_x, X,\n",
    "        grad_outputs=torch.ones_like(u_x),\n",
    "        create_graph=True,\n",
    "        retain_graph=True)[0][:, 1]\n",
    "    fu = u_t + u[:, 0] * u_x - nu * u_xx\n",
    "    return u, fu\n",
    "\n",
    "\n",
    "loss_function = nn.MSELoss()\n",
    "lam0 = 5.0\n",
    "lamB = 5.0\n",
    "\n",
    "def loss(fu, u0, u0pinn, ul, ulpinn, ur, urpinn):\n",
    "    Ntot = fu.shape[0]\n",
    "    zeros = torch.zeros((Ntot, 1), dtype=torch.get_default_dtype(), device=fu.device)\n",
    "    fu_col = fu.reshape(-1, 1)\n",
    "    loss_value = (loss_function(fu_col, zeros)\n",
    "                  + lam0 * loss_function(u0, u0pinn)\n",
    "                  + lamB * (loss_function(ul, ulpinn) + loss_function(ur, urpinn)))\n",
    "    return loss_value\n",
    "\n",
    "def grads(N, X, X0, Xb):\n",
    "    for p in N.parameters():\n",
    "        p.grad = None\n",
    "\n",
    "    X = X.clone().detach().requires_grad_(True)\n",
    "    X0 = X0.clone().detach().requires_grad_(True)\n",
    "    _, fu = get_results(N, X)\n",
    "    u0 = uinit(X0)\n",
    "    u0pinn = output(N, X0)\n",
    "    ul = uleft(Xb)\n",
    "    ur = uright(Xb)\n",
    "    mask_l = (Xb[:, 1] == x0)\n",
    "    mask_r = (Xb[:, 1] == xf)\n",
    "    ulpinn = output(N, Xb[mask_l])\n",
    "    urpinn = output(N, Xb[mask_r])\n",
    "\n",
    "    loss_value = loss(fu, u0, u0pinn, ul, ulpinn, ur, urpinn)\n",
    "\n",
    "    loss_value.backward()\n",
    "\n",
    "    gradsN = [p.grad for p in N.parameters()]\n",
    "    return gradsN, loss_value\n",
    "\n",
    "\n",
    "def training(N, X, X0, Xb, optimizer):\n",
    "    _, loss_value = grads(N, X, X0, Xb)\n",
    "    optimizer.step()\n",
    "    return loss_value\n",
    "\n",
    "\n",
    "X  = generate_inputs(Nint)\n",
    "X0 = initial_points(N0)\n",
    "Xb = boundary_points(Nb)\n",
    "\n",
    "\n",
    "template = 'Epoch {}, loss: {}'\n",
    "\n",
    "rel_adam = [] \n",
    "optimizer = torch.optim.Adam(N.parameters(), lr=5e-3, betas=(0.99, 0.999), eps=1e-20)\n",
    "adam_scheduler = torch.optim.lr_scheduler.LambdaLR(\n",
    "    optimizer, lr_lambda=lambda step: 0.98 ** (step / 1000.0))\n",
    "\n",
    "adam_losses = []\n",
    "start_time = perf_counter()\n",
    "\n",
    "adam_t0 = perf_counter()\n",
    "for epoch in range(Nepochs_ADAM):\n",
    "    if (epoch + 1) % Nchange == 0:\n",
    "        X  = adaptive_rad(N, Nint, rad_args)\n",
    "        X0 = initial_points(N0)\n",
    "        Xb = boundary_points(Nb)\n",
    "\n",
    "    loss_value = training(N, X, X0, Xb, optimizer)\n",
    "    adam_losses.append(float(loss_value.detach().cpu().item()))\n",
    "\n",
    "    if (epoch + 1) % Nprint == 0:\n",
    "        print(template.format(epoch + 1, adam_losses[-1]))\n",
    "\n",
    "        N.eval()\n",
    "        with torch.no_grad():\n",
    "            u_pred = output(N, X_star).detach().cpu().numpy().reshape(u_ref.shape)\n",
    "        N.train()\n",
    "\n",
    "        num = np.linalg.norm(u_ref - u_pred)\n",
    "        den = np.linalg.norm(u_pred) + 1e-12\n",
    "        rel = num / den\n",
    "        rel_adam.append((epoch + 1, float(rel)))\n",
    "\n",
    "\n",
    "adam_time_sec = perf_counter() - adam_t0\n",
    "\n",
    "def nested_tensor(grad, layer_dims, train_activations=False, bias=True):\n",
    "    if _has_torch and isinstance(grad, torch.Tensor):\n",
    "        grad = grad.detach().cpu().numpy()\n",
    "    grad = np.asarray(grad).ravel()\n",
    "\n",
    "    if not train_activations:\n",
    "        if bias:\n",
    "            temp = [None] * (2 * len(layer_dims) - 2)  \n",
    "        else:\n",
    "            temp = [None] * (2 * len(layer_dims) - 3) \n",
    "\n",
    "        index = 0\n",
    "        for i in range(len(temp)):\n",
    "            if i % 2 == 0:\n",
    "                k = i // 2\n",
    "                fan_in, fan_out = layer_dims[k], layer_dims[k + 1]\n",
    "                expected_shape = (fan_in, fan_out)\n",
    "                size = fan_in * fan_out\n",
    "\n",
    "                print('layer_dims', layer_dims)\n",
    "                print(f\"Expected shape: {expected_shape}, Grad slice size: {size}\")\n",
    "                print(f\"Current index: {index}, Next index: {index + size}\")\n",
    "                print(f\"Size of grad slice: {grad[index:index+size].size}\")\n",
    "\n",
    "                temp[i] = grad[index:index + size].reshape(expected_shape)\n",
    "                index += size\n",
    "            else:\n",
    "                k = i - (i // 2)       \n",
    "                bsz = layer_dims[k]\n",
    "                temp[i] = grad[index:index + bsz]\n",
    "                index += bsz\n",
    "        return temp\n",
    "\n",
    "    else:\n",
    "        temp = [None] * (3 * len(layer_dims) - 4)\n",
    "        index = 0\n",
    "        for i in range(len(temp)):\n",
    "            if i % 3 == 0:\n",
    "          \n",
    "                k = i // 3\n",
    "                fan_in, fan_out = layer_dims[k], layer_dims[k + 1]\n",
    "                size = fan_in * fan_out\n",
    "                temp[i] = grad[index:index + size].reshape(fan_in, fan_out)\n",
    "                index += size\n",
    "            elif i % 3 == 1:\n",
    "\n",
    "                k = int((i + 2) / 3)  \n",
    "                bsz = layer_dims[k]\n",
    "                temp[i] = grad[index:index + bsz]\n",
    "                index += bsz\n",
    "            else:\n",
    "  \n",
    "                temp[i] = grad[index]\n",
    "                index += 1\n",
    "        return temp\n",
    "\n",
    "\n",
    "power = 1.0  \n",
    "\n",
    "def loss_and_gradient_torch(N, X, X0, Xb, power=power):\n",
    "    X = X.clone().detach().requires_grad_(True)\n",
    "    _, fu = get_results(N, X)\n",
    "    u0 = uinit(X0)\n",
    "    u0pinn = output(N, X0)\n",
    "    ul = uleft(Xb)\n",
    "    mask_l = (Xb[:, 1] == x0)\n",
    "    ulpinn = output(N, Xb[mask_l])\n",
    "    ur = uright(Xb)\n",
    "    mask_r = (Xb[:, 1] == xf)\n",
    "    urpinn = output(N, Xb[mask_r])\n",
    "    loss_value = loss(fu, u0, u0pinn, ul, ulpinn, ur, urpinn)\n",
    "    loss_root = loss_value if power == 1.0 else loss_value ** (1.0 / power)\n",
    "    params = list(N.parameters())\n",
    "    gradsN = torch.autograd.grad(\n",
    "        loss_root, params,\n",
    "        create_graph=False, retain_graph=False, allow_unused=False)\n",
    "    return loss_root, gradsN\n",
    "\n",
    "\n",
    "def loss_and_gradient(weights, N, X, X0, Xb, layer_dims=None):\n",
    "    first_param = next(N.parameters())\n",
    "    device = first_param.device\n",
    "    dtype = first_param.dtype\n",
    "    w_tensor = torch.as_tensor(weights, dtype=dtype, device=device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        vector_to_parameters(w_tensor, N.parameters())\n",
    "    loss_val, grads_list = loss_and_gradient_torch(N, X, X0, Xb, power=power)\n",
    "    grads_flat = torch.cat([g.reshape(-1) for g in grads_list])\n",
    "\n",
    "    return float(loss_val.detach().cpu().item()), grads_flat.detach().cpu().numpy()\n",
    "\n",
    "\n",
    "Nbfgs = 10000\n",
    "Nbatches = int(round(Nbfgs / Nchange))\n",
    "Nprint = 100\n",
    "n_ckpts        = Nbfgs // Nprint                  \n",
    "warmup_steps   = len(adam_losses)                  \n",
    "epochs_bfgs    = warmup_steps + np.arange(1, n_ckpts + 1, dtype=float) * Nprint\n",
    "lossbfgs        = np.zeros(n_ckpts, dtype=float)\n",
    "validation_list = np.zeros(n_ckpts, dtype=float)\n",
    "error_list      = np.zeros(n_ckpts, dtype=float)\n",
    "time_elapsed = np.array([])  \n",
    "initial_time = perf_counter()\n",
    "\n",
    "Nt = 300\n",
    "Nx = 300\n",
    "Xtest, t, x = generate_validation(Nt, Nx)\n",
    "X0test = Xtest[:Nx]\n",
    "mask_b = (Xtest[:, 1] == x0) | (Xtest[:, 1] == xf)\n",
    "Xbtest = Xtest[mask_b]\n",
    "\n",
    "mat = scipy.io.loadmat(\"burgers_canonical.mat\")\n",
    "u_ref  = mat[\"usol\"]\n",
    "t_star = mat[\"t\"].ravel()\n",
    "x_star = mat[\"x\"].ravel()\n",
    "x_star, t_star = np.meshgrid(x_star, t_star)\n",
    "\n",
    "device = next(N.parameters()).device\n",
    "X_star = torch.as_tensor(\n",
    "    np.hstack((t_star.reshape(-1,1), x_star.reshape(-1,1))),\n",
    "    dtype=torch.get_default_dtype(),\n",
    "    device=device)\n",
    "\n",
    "\n",
    "initial_weights = parameters_to_vector([p.detach() for p in N.parameters()]).cpu().numpy()\n",
    "\n",
    "cont = 0\n",
    "def callback(*, intermediate_result):\n",
    "    global N, cont, lossbfgs, Nprint, u_ref, \\\n",
    "           x_star, X_star, Xtest, validation_list, X0test, Xbtest, error_list, power\n",
    "\n",
    "    device = next(N.parameters()).device\n",
    "    dtype  = next(N.parameters()).dtype\n",
    "\n",
    "    cont += 1\n",
    "    if (cont % Nprint) != 0:\n",
    "        return\n",
    "\n",
    "    idx = cont // Nprint - 1\n",
    "    if idx < 0 or idx >= len(lossbfgs):  # guard\n",
    "        return\n",
    "\n",
    "    loss_value = float((intermediate_result.fun) ** power)\n",
    "    lossbfgs[idx] = loss_value\n",
    "\n",
    "    _, futest = get_results(N, Xtest.to(device))\n",
    "    zeros = torch.zeros((futest.shape[0], 1), dtype=dtype, device=device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        u_pred = output(N, X_star).reshape(x_star.shape)        \n",
    "        u_ref_t = torch.as_tensor(u_ref, dtype=dtype, device=device)\n",
    "        v1 = loss_function(u_pred, u_ref_t)\n",
    "        v2 = loss_function(futest.reshape(-1,1), zeros)\n",
    "        validation_list[idx] = (v1 + v2).item()\n",
    "\n",
    "    u_np = u_pred.detach().cpu().numpy()\n",
    "    num = np.linalg.norm(u_ref - u_np)\n",
    "    den = np.linalg.norm(u_np) + 1e-12\n",
    "    error_list[idx] = num / den\n",
    "\n",
    "    print(f\"Iteration {cont} (ckpt {idx+1}/{len(lossbfgs)}): \"\n",
    "          f\"Train {loss_value:.3e}, relL2 {error_list[idx]:.3e}\")\n",
    "\n",
    "\n",
    "method = \"BFGS\"\n",
    "method_bfgs = \"SSBroyden2\"      \n",
    "initial_scale = False      \n",
    "warmup_tag = \"warmup_adam\" \n",
    "\n",
    "os.makedirs(\"results2\", exist_ok=True)\n",
    "\n",
    "def _scipy_cb_factory():\n",
    "    class _Res:\n",
    "        __slots__ = (\"fun\",)\n",
    "        def __init__(self, fun): self.fun = fun\n",
    "    def _cb(xk):\n",
    "        f, _ = loss_and_gradient(xk, N, X, X0, Xb, layer_dims)\n",
    "        callback(intermediate_result=_Res(f))\n",
    "    return _cb\n",
    "\n",
    "H0 = np.eye(initial_weights.size, dtype=np.float64)\n",
    "\n",
    "initial_time_bfgs = perf_counter()\n",
    "\n",
    "bfgs_loss_ckpt = []\n",
    "bfgs_rel       = []\n",
    "\n",
    "bfgs_t0 = perf_counter()\n",
    "\n",
    "while cont < Nbfgs: \n",
    "    print(cont)\n",
    "    result = minimize(\n",
    "        loss_and_gradient, \n",
    "        initial_weights, \n",
    "        args=(N, X, X0, Xb, layer_dims),\n",
    "        method=method,\n",
    "        jac=True,\n",
    "        options={\n",
    "            'maxiter': Nchange,\n",
    "            'gtol': 0,\n",
    "            'hess_inv0': H0,          \n",
    "            'method_bfgs': method_bfgs,\n",
    "            'initial_scale': initial_scale },\n",
    "        tol=0,\n",
    "        callback=callback) \n",
    "\n",
    "    initial_weights = result.x\n",
    "    H0 = result.hess_inv\n",
    "    H0 = 0.5 * (H0 + H0.T)\n",
    "    \n",
    "    try:\n",
    "        cholesky(H0)\n",
    "    except LinAlgError:\n",
    "        H0 = np.eye(len(initial_weights), dtype=np.float64) \n",
    "\n",
    "    X  = adaptive_rad(N, Nint, rad_args)\n",
    "    X0 = initial_points(N0)\n",
    "    Xb = boundary_points(Nb)\n",
    "    _, fu   = get_results(N, X)\n",
    "    u0      = uinit(X0)\n",
    "    u0pinn  = output(N, X0)\n",
    "    ul      = uleft(Xb)\n",
    "    ulpinn  = output(N, Xb[Xb[:, 1] == x0])\n",
    "    ur      = uright(Xb)\n",
    "    urpinn  = output(N, Xb[Xb[:, 1] == xf])\n",
    "    loss_value = loss(fu, u0, u0pinn, ul, ulpinn, ur, urpinn)\n",
    "\n",
    "    initial_scale = False\n",
    "\n",
    "bfgs_time_sec = perf_counter() - bfgs_t0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97de3809-66b3-4aba-b621-fb46b5a1545e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b626670-44fc-4aef-8ff4-ead2c2adc700",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
